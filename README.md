This repository is part of our publication in the 20th International Conference on Mining Software Repositories (MSR 2023). If you use LLMSecEval in academic context, please cite it as follows:

    @inproceedings{llmseceval2023,
      title     = {LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations},  
      author    = {Tony, Catherine and Mutas, Markus and DÃ­az Ferreyra, Nicolas and Scandariato, Riccardo},  
      booktitle = {2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)},   
      year      = {2023},
      doi       = {10.5281/zenodo.7565965}
    }

# LLMSecEval: Dataset of NL Prompts for Code Generation

This repo consists of a dataset of NL prompts that can be used to generate code using LLMs (Large Language Models) that cover different security scenarios. The prompts cover 18 out of Top 25 CWEs scenarios of 2021. The primary usage of this dataset is to evaluate the code generated by different LLMs in terms of security. Additionally it can also be used to explore the field of prompt engineering to generate secure code using LLMs. The dataset is largely language-agnostic such that it can be used to generate code in any programming language. The dataset and its usage instructions can be found in the folder: [Dataset](https://github.com/tuhh-softsec/LLMSecEval/tree/main/Dataset).

In addition to the dataset, we have created a web application that can be used to generated code from NL prompts using GPT-3 and Codex. It also includes the functionality for generating NL descriptions from code snippets. This is to enable the extension of the NL prompts dataset. The code and usage instructions of this application can be found in the folder: [Code Generation](https://github.com/tuhh-softsec/LLMSecEval/tree/main/Code%20Generation).

And finally, an interface to detect vulnerabilities associated with 18 out of the top 25 CWEs using CodeQL queries is present in the folder: [Security Analysis - CodeQL](https://github.com/tuhh-softsec/LLMSecEval/tree/main/Security%20Analysis%20-%20CodeQL).
